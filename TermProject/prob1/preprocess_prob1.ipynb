{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"preprocess_prob1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"id":"X3-YpOofy0zO","colab_type":"code","outputId":"8ee91da7-c371-4039-8f07-ed542d8faec3","executionInfo":{"status":"ok","timestamp":1576720980889,"user_tz":-540,"elapsed":2558,"user":{"displayName":"Khi nenw","photoUrl":"","userId":"08455783256192856833"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import pickle\n","import h5py\n","import re\n","import tqdm\n","import numpy as np\n","import pandas as pd\n","import gzip\n","\n","from collections import Counter\n","from keras.utils.np_utils import to_categorical\n","\n","re_sc = re.compile('[\\!@#$%\\^&\\*\\(\\)-=\\[\\]\\{\\}\\.,/\\?~\\+\\'\"|]')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"WO7sFdK1y0zV","colab_type":"code","outputId":"66b00227-5a50-462a-cb8f-a970f137aaf0","executionInfo":{"status":"ok","timestamp":1576720998641,"user_tz":-540,"elapsed":20295,"user":{"displayName":"Khi nenw","photoUrl":"","userId":"08455783256192856833"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lyYrQ7jNy0zZ","colab_type":"text"},"source":["### Load the raw file"]},{"cell_type":"code","metadata":{"id":"Bk1jMyWIy0za","colab_type":"code","outputId":"2b8146fe-41d2-41bf-b7ca-d13b8a2faf5c","executionInfo":{"status":"ok","timestamp":1576721003758,"user_tz":-540,"elapsed":25401,"user":{"displayName":"Khi nenw","photoUrl":"","userId":"08455783256192856833"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["df = pd.read_csv('./drive/My Drive/CoE202TermProject/datasets/train.chunk.csv', encoding='utf-8')\n","\n","df.head(5)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pid</th>\n","      <th>brand</th>\n","      <th>model</th>\n","      <th>maker</th>\n","      <th>product</th>\n","      <th>price</th>\n","      <th>bcateid</th>\n","      <th>mcateid</th>\n","      <th>scateid</th>\n","      <th>dcateid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>O4486751463</td>\n","      <td>퍼즐라이프</td>\n","      <td>퍼즐라이프 직소퍼즐 바다거북의 여행</td>\n","      <td>상품상세설명 참조</td>\n","      <td>직소퍼즐 - 1000조각 바다거북의 여행 (PL1275)</td>\n","      <td>16520</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>P3307178849</td>\n","      <td>바보사랑</td>\n","      <td>아이폰6S/6S+ tree farm101 - 다이어리케이스|아이폰6S/6S+</td>\n","      <td>MORY|해당없음</td>\n","      <td>[모리케이스]아이폰6S/6S+ tree farm101 - 다이어리케이스[바보사랑][...</td>\n","      <td>20370</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>R4424255515</td>\n","      <td>크리비아</td>\n","      <td>크리비아 기모 3부 속바지 GLG4314P</td>\n","      <td>NaN</td>\n","      <td>크리비아 기모 3부 속바지 GLG4314P</td>\n","      <td>-1</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>F3334315393</td>\n","      <td>잭앤질</td>\n","      <td>[잭앤질] 남성 솔리드 절개라인 포인트 포켓 팬츠 31133PT002_NA</td>\n","      <td>㈜크리스패션</td>\n","      <td>[하프클럽/잭앤질]남성 솔리드 절개라인 포인트 포켓 팬츠 31133PT002_NA</td>\n","      <td>16280</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>N731678492</td>\n","      <td>NaN</td>\n","      <td>SD코드프리혈당시험지[50매]</td>\n","      <td>기타</td>\n","      <td>코드프리혈당시험지50매/코드프리시험지/최장유효기간</td>\n","      <td>-1</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>11</td>\n","      <td>-1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           pid  brand  ... scateid dcateid\n","0  O4486751463  퍼즐라이프  ...       2      -1\n","1  P3307178849   바보사랑  ...       4      -1\n","2  R4424255515   크리비아  ...       6      -1\n","3  F3334315393    잭앤질  ...       8      -1\n","4   N731678492    NaN  ...      11      -1\n","\n","[5 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"w0Mw9kH-y0ze","colab_type":"text"},"source":["### Build label dictionary"]},{"cell_type":"code","metadata":{"id":"64RU-ZKly0ze","colab_type":"code","outputId":"d58912cb-79b3-4de1-a5c2-d362214f3666","executionInfo":{"status":"ok","timestamp":1576721045341,"user_tz":-540,"elapsed":66976,"user":{"displayName":"Khi nenw","photoUrl":"","userId":"08455783256192856833"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["y_vocab = {}                                          # Define dictionary for labels\n","\n","sz = df['pid'].shape[0]                               # The number of data, 800,000 here\n","for i in tqdm.tqdm(range(sz), mininterval=1):         # tqdm predict the remaining time during for loop\n","    b = df['bcateid'][i]                              # Get category 1\n","    m = df['mcateid'][i]                              # Get category 2\n","    s = df['scateid'][i]                              # Get category 3\n","    d = df['dcateid'][i]                              # Get category 4\n","    class_name = '{}>{}>{}>{}'.format(b, m ,s, d)     # Combine four categories\n","    if class_name not in y_vocab:                     # If the combination of categories isn't in dictionary, add it to dictionary.\n","        y_vocab[class_name] = len(y_vocab)\n","    \n","y_dict = {y: idx for idx, y in enumerate(y_vocab)}\n","pickle.dump(y_dict, open('./drive/My Drive/CoE202TermProject/datasets/y_vocab.pickle', 'wb'), 2)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["100%|██████████| 800000/800000 [00:41<00:00, 19340.44it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Pf1olVFRy0zh","colab_type":"text"},"source":["### Parse the input data"]},{"cell_type":"code","metadata":{"id":"6IUxIxyEy0zi","colab_type":"code","colab":{}},"source":["def preprocess(df, save_label = True):\n","    sz = df['pid'].shape[0]\n","    products, labels = [], []\n","\n","    for i in tqdm.tqdm(range(sz), mininterval=1):\n","        if save_label:\n","            b = df['bcateid'][i]\n","            m = df['mcateid'][i]\n","            s = df['scateid'][i]\n","            d = df['dcateid'][i]\n","            class_name = '{}>{}>{}>{}'.format(b, m ,s, d)\n","            \n","            # label\n","            labels_i = y_dict.get(class_name)\n","            labels.append(labels_i)\n","        \n","        else:\n","            labels.append(df['pid'][i])\n","\n","        words_i = np.zeros(32, dtype=np.int32)\n","        word_counts_i = np.zeros(32, dtype=np.int8)\n","\n","        feature = df['product'][i]                                # Get the product name\n","        if isinstance(feature, str) and not pd.isnull(feature):         # Check the product name is string or empty\n","            feature = re_sc.sub(' ', feature).strip().split()     # re_sc eliminate the special symbols (!@#$\"...)\n","                                                                # strip() is a function to remove blank before and after of strings\n","                                                                # split() is the function of separating strings based on spaces.\n","            words = [w.strip() for w in feature]                  # Make seperated words to list\n","            words = [w for w in words                             \n","                    if len(w) >= 2 and len(w) < 31]               # If each word is less than 2 and more than 31 is discarded.\n","\n","            x = [hash(w) % 100000 + 1 for w in words]             # Mapping words to integer using hash function\n","            xv = Counter(x).most_common(32)                       # Count the number of words in a string\n","\n","            for j in range(len(xv)):\n","                words_i[j] = xv[j][0]                                   # Mapped integers of words\n","                word_counts_i[j] = xv[j][1]                                   # Counts of words\n","        \n","        brand = df['brand'][i]\n","        brand_i = 0\n","        if isinstance(brand, str) and not pd.isnull(brand) and brand and \\\n","            \"상세\" not in brand and \"참조\" not in brand:\n","\n","            # As brand is nearly one word, we can just use it\n","            brand = re_sc.sub('', brand)\n","            brand_i = hash(brand) % 100000 + 1\n","\n","\n","        model = df['model'][i]\n","        model_i = np.zeros(32, dtype=np.int32)\n","        model_counts_i = np.zeros(32, dtype=np.int8)\n","        if isinstance(model, str) and not pd.isnull(model) and model:\n","            model = re_sc.sub(' ', model).strip().split()\n","            words = [w.strip() for w in model]                  # Make seperated words to list\n","            words = [w for w in words                             \n","                    if len(w) >= 2 and len(w) < 31]\n","            \n","            x = [hash(w) % 100000 + 1 for w in words]             # Mapping words to integer using hash function\n","            xv = Counter(x).most_common(32)                       # Count the number of words in a string\n","\n","            for j in range(len(xv)):\n","                model_i[j] = xv[j][0]                                   # Mapped integers of words\n","                model_counts_i[j] = xv[j][1]\n","\n","\n","        maker = df['maker'][i]\n","        maker_i = 0\n","        if isinstance(maker, str) and not pd.isnull(maker) and maker and \\\n","            \"상세\" not in maker and \"참조\" not in maker:\n","\n","            # As maker is nearly one word, we can just use it\n","            maker = re_sc.sub('', maker)\n","            maker_i = hash(maker) % 100000 + 1\n","        \n","        price = df['price'][i]\n","        price_i = 0\n","\n","        if not pd.isnull(price):\n","            price_i = price\n","        \n","        products.append(np.asarray([\n","            brand_i, model_i, model_counts_i, maker_i,\n","            words_i, word_counts_i, price_i\n","        ]))\n","    \n","    # products = np.transpose(np.asarray(products))\n","    products = np.asarray(products)\n","\n","    return products, np.asarray(labels)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eTQD92nOy0zn","colab_type":"text"},"source":["### Save the input vectors"]},{"cell_type":"code","metadata":{"id":"MGQRX9sju7er","colab_type":"code","outputId":"cdb1c7f7-f0c0-441e-f18c-6dcdbb99fc0b","executionInfo":{"status":"ok","timestamp":1576721319682,"user_tz":-540,"elapsed":341304,"user":{"displayName":"Khi nenw","photoUrl":"","userId":"08455783256192856833"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["products, labels = preprocess(df)\n","\n","train_dset = {\n","    'product': np.asarray(products), 'label': np.asarray(labels)\n","}\n","\n","with gzip.open('./drive/My Drive/CoE202TermProject/datasets/train.chunk.pickle', 'wb') as f:\n","    pickle.dump(train_dset, f)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["100%|██████████| 800000/800000 [02:51<00:00, 4668.93it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"qh9lI5SYy0zr","colab_type":"text"},"source":["### Parse the validation dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"e3b27120-26f8-423f-c956-1cf71e397f1c","id":"OG-_JpMbTPER","executionInfo":{"status":"ok","timestamp":1576721361418,"user_tz":-540,"elapsed":383031,"user":{"displayName":"Khi nenw","photoUrl":"","userId":"08455783256192856833"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df = pd.read_csv('./drive/My Drive//CoE202TermProject/datasets/valid.chunk.csv')\n","products, labels = preprocess(df)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["100%|██████████| 178830/178830 [00:40<00:00, 4462.55it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"edeoatd-y0zt","colab_type":"text"},"source":["### Save the validation vectors"]},{"cell_type":"code","metadata":{"id":"VpxyNWkQvyzP","colab_type":"code","colab":{}},"source":["valid_dset = {'product': np.asarray(products), 'label': np.asarray(labels)}\n","\n","with gzip.open('./drive/My Drive/CoE202TermProject/datasets/valid.chunk.pickle', 'wb') as f:\n","    pickle.dump(valid_dset, f)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dtWsBHsBy0zv","colab_type":"text"},"source":["### Parse the test dataset"]},{"cell_type":"code","metadata":{"id":"VXLUb7YVy0zv","colab_type":"code","outputId":"a1f5b262-20c4-4f52-ddd9-dc15dd622ca9","executionInfo":{"status":"ok","timestamp":1576721416494,"user_tz":-540,"elapsed":438098,"user":{"displayName":"Khi nenw","photoUrl":"","userId":"08455783256192856833"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df = pd.read_csv('./drive/My Drive/CoE202TermProject/datasets/test.chunk.csv')\n","products, pids = preprocess(df, False)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["100%|██████████| 178830/178830 [00:30<00:00, 5855.05it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"zPVuXmv9y0zz","colab_type":"text"},"source":["### Save the test vectors"]},{"cell_type":"code","metadata":{"id":"o4pK3tXvxJ8y","colab_type":"code","colab":{}},"source":["test_dset = {'product': np.asarray(products), 'pids': np.asarray(pids)}\n","\n","with gzip.open('./drive/My Drive/CoE202TermProject/datasets/test.chunk.pickle', 'wb') as f:\n","    pickle.dump(test_dset, f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xblutzHGbvRB","colab_type":"code","outputId":"5802237f-156a-413d-9e07-9efa0b836be5","executionInfo":{"status":"ok","timestamp":1576721448774,"user_tz":-540,"elapsed":470368,"user":{"displayName":"Khi nenw","photoUrl":"","userId":"08455783256192856833"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pids[0]"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'T4364497649'"]},"metadata":{"tags":[]},"execution_count":11}]}]}