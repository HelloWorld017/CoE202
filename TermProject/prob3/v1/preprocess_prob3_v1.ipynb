{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess_prob3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP_W5GCMhpwS",
        "colab_type": "text"
      },
      "source": [
        "## Initialize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agcNBgVjU5Gr",
        "colab_type": "text"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZkBKkhkVC_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "from collections import Counter\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9uZwVDVhiJv",
        "colab_type": "text"
      },
      "source": [
        "### Defining some constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4HCvHV-iBKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re_sc = re.compile(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9 ]\")\n",
        "base_path = '.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlDsF4QLiGGA",
        "colab_type": "text"
      },
      "source": [
        "### Mounting File System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JaYRzR1VlOw",
        "colab_type": "code",
        "outputId": "5eda07a5-317e-42cb-a955-38b200b38f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_path = './drive/My Drive/CoE202TermProject'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02tsZ_crVpSZ",
        "colab_type": "text"
      },
      "source": [
        "## Building Label Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBUD5IMriyFH",
        "colab_type": "text"
      },
      "source": [
        "### Load Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1akjlg6VuFs",
        "colab_type": "code",
        "outputId": "17fbd86e-ef1c-41f7-d77c-68d8fe87122a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "df = pd.read_csv(\n",
        "    base_path + '/datasets/train.chunk.csv',\n",
        "    encoding='utf-8'\n",
        ")\n",
        "\n",
        "df.head(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pid</th>\n",
              "      <th>brand</th>\n",
              "      <th>model</th>\n",
              "      <th>maker</th>\n",
              "      <th>product</th>\n",
              "      <th>price</th>\n",
              "      <th>bcateid</th>\n",
              "      <th>mcateid</th>\n",
              "      <th>scateid</th>\n",
              "      <th>dcateid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O4486751463</td>\n",
              "      <td>퍼즐라이프</td>\n",
              "      <td>퍼즐라이프 직소퍼즐 바다거북의 여행</td>\n",
              "      <td>상품상세설명 참조</td>\n",
              "      <td>직소퍼즐 - 1000조각 바다거북의 여행 (PL1275)</td>\n",
              "      <td>16520</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P3307178849</td>\n",
              "      <td>바보사랑</td>\n",
              "      <td>아이폰6S/6S+ tree farm101 - 다이어리케이스|아이폰6S/6S+</td>\n",
              "      <td>MORY|해당없음</td>\n",
              "      <td>[모리케이스]아이폰6S/6S+ tree farm101 - 다이어리케이스[바보사랑][...</td>\n",
              "      <td>20370</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>R4424255515</td>\n",
              "      <td>크리비아</td>\n",
              "      <td>크리비아 기모 3부 속바지 GLG4314P</td>\n",
              "      <td>NaN</td>\n",
              "      <td>크리비아 기모 3부 속바지 GLG4314P</td>\n",
              "      <td>-1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>F3334315393</td>\n",
              "      <td>잭앤질</td>\n",
              "      <td>[잭앤질] 남성 솔리드 절개라인 포인트 포켓 팬츠 31133PT002_NA</td>\n",
              "      <td>㈜크리스패션</td>\n",
              "      <td>[하프클럽/잭앤질]남성 솔리드 절개라인 포인트 포켓 팬츠 31133PT002_NA</td>\n",
              "      <td>16280</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>N731678492</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SD코드프리혈당시험지[50매]</td>\n",
              "      <td>기타</td>\n",
              "      <td>코드프리혈당시험지50매/코드프리시험지/최장유효기간</td>\n",
              "      <td>-1</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pid  brand  ... scateid dcateid\n",
              "0  O4486751463  퍼즐라이프  ...       2      -1\n",
              "1  P3307178849   바보사랑  ...       4      -1\n",
              "2  R4424255515   크리비아  ...       6      -1\n",
              "3  F3334315393    잭앤질  ...       8      -1\n",
              "4   N731678492    NaN  ...      11      -1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfhgoBWkV3R5",
        "colab_type": "text"
      },
      "source": [
        "### Build"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwndB7K5WHTz",
        "colab_type": "code",
        "outputId": "0b380030-7f02-44d1-dc5a-2472a69317ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_vocab = {}\n",
        "\n",
        "def item_to_class_name(df, i):\n",
        "    b = df['bcateid'][i]\n",
        "    m = df['mcateid'][i]\n",
        "    s = df['scateid'][i]\n",
        "    d = df['dcateid'][i]\n",
        "\n",
        "    return '{}>{}>{}>{}'.format(b, m, s, d)\n",
        "\n",
        "size = df['pid'].shape[0]\n",
        "for i in tqdm(range(size)):\n",
        "    class_name = item_to_class_name(df, i)\n",
        "    if class_name not in y_vocab:\n",
        "        y_vocab[class_name] = len(y_vocab)\n",
        "\n",
        "y_dict = {y: idx for idx, y in enumerate(y_vocab)}\n",
        "\n",
        "pickle.dump(y_dict, open(base_path + '/datasets/y_vocab.pickle', 'wb'), 2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 800000/800000 [00:36<00:00, 22061.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih4EisCMWwyX",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnUawNBjc_th",
        "colab_type": "text"
      },
      "source": [
        "### Defining Helper Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEd2NjSDWy_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_vocab = {}\n",
        "\n",
        "def add_to_vocab(word):\n",
        "    word_id = 0\n",
        "    if word not in x_vocab:\n",
        "        word_id = len(x_vocab)\n",
        "        x_vocab[word] = [word_id, 1]\n",
        "    \n",
        "    else:\n",
        "        word_item = x_vocab[word]\n",
        "        word_item[1] += 1\n",
        "        word_id = word_item[0]\n",
        "\n",
        "    return word_id\n",
        "\n",
        "def parse_word(word):\n",
        "    word = re_sc.sub('', word)\n",
        "    return add_to_vocab(word)\n",
        "\n",
        "def parse_long_text(text, max_size=32):\n",
        "    text = re_sc.sub(' ', text).strip()\n",
        "    words = text.split()\n",
        "    words = [w.strip() for w in words]\n",
        "    words = [w for w in words if len(w) >= 2]\n",
        "\n",
        "    if len(words) < 1:\n",
        "        return []\n",
        "        # return [], []\n",
        "    \n",
        "    x = [add_to_vocab(w) for w in words][:max_size]\n",
        "    return list(x)\n",
        "\n",
        "    # x_counter = Counter(x).most_common(max_size)\n",
        "    # return zip(*x_counter)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5I4k0I-c6n6",
        "colab_type": "text"
      },
      "source": [
        "### Defining Preprocessing Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSgIvIvBc3PC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(df, save_label = True):\n",
        "    sz = df['pid'].shape[0]\n",
        "    features, labels = [], []\n",
        "\n",
        "    for i in tqdm(range(sz)):\n",
        "        if save_label:\n",
        "            class_name = item_to_class_name(df, i)\n",
        "            labels.append(y_dict.get(class_name))\n",
        "        \n",
        "        else:\n",
        "            labels.append(df['pid'][i])\n",
        "\n",
        "        # Parsing 'brand'\n",
        "        brand = df['brand'][i]\n",
        "        brand_i = 0\n",
        "        if isinstance(brand, str) and not pd.isnull(brand) and brand and \\\n",
        "            \"상세\" not in brand and \"참조\" not in brand:\n",
        "\n",
        "            brand_i = parse_word(brand)\n",
        "        \n",
        "        # Parsing 'model'\n",
        "        model = df['model'][i]\n",
        "        model_i = np.zeros(16, dtype=np.int32)\n",
        "        # model_counts_i = np.zeros(16, dtype=np.int8)\n",
        "        if isinstance(model, str) and not pd.isnull(model) and model:\n",
        "            # model_words, model_word_counts = parse_long_text(model, 16)\n",
        "            model_words = parse_long_text(model, 16)\n",
        "\n",
        "            for j in range(len(model_words)):\n",
        "                model_i[j] = model_words[j]\n",
        "                # model_counts_i[j] = model_word_counts[j]\n",
        "        \n",
        "        # Parsing 'maker'\n",
        "        maker = df['maker'][i]\n",
        "        maker_i = 0\n",
        "        if isinstance(maker, str) and not pd.isnull(maker) and maker and \\\n",
        "            \"상세\" not in maker and \"참조\" not in maker:\n",
        "            \n",
        "            maker_i = parse_word(maker)\n",
        "        \n",
        "        # Parsing 'product'\n",
        "        product = df['product'][i]\n",
        "        product_i = np.zeros(32, dtype=np.int32)\n",
        "        # product_counts_i = np.zeros(32, dtype=np.int8)\n",
        "        if isinstance(product, str) and not pd.isnull(product) and product:\n",
        "            # product_words, product_word_counts = parse_long_text(product)\n",
        "            product_words = parse_long_text(product, 32)\n",
        "\n",
        "            for j in range(len(product_words)):\n",
        "                product_i[j] = product_words[j]\n",
        "                # product_counts_i[j] = product_word_counts[j]\n",
        "\n",
        "        # Parsing 'price'\n",
        "        price = df['price'][i]\n",
        "        price_i = 0\n",
        "\n",
        "        if not pd.isnull(price):\n",
        "            price_i = price\n",
        "        \n",
        "        features.append(np.asarray([\n",
        "            brand_i,\n",
        "            model_i,\n",
        "            # model_i, model_counts_i,\n",
        "            maker_i,\n",
        "            product_i,\n",
        "            # product_i, product_counts_i,\n",
        "            price_i\n",
        "        ]))\n",
        "\n",
        "    return features, labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdOytm35hCcJ",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing Train Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xt9LwsAhV9C",
        "colab_type": "code",
        "outputId": "6d34f294-9d6e-48da-f975-ea147994d822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "features, labels = preprocess(df)\n",
        "train_dset = {\n",
        "    'features': np.asarray(features),\n",
        "    'labels': np.asarray(labels)\n",
        "}\n",
        "\n",
        "with gzip.open(base_path + '/datasets/train.chunk.pickle', 'wb') as f:\n",
        "    pickle.dump(train_dset, f)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 800000/800000 [01:59<00:00, 6674.55it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkoAOxuijAuE",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEDp3LeNjCZ_",
        "colab_type": "code",
        "outputId": "74263503-7e53-444e-e2cb-141220f23f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = pd.read_csv(\n",
        "    base_path + '/datasets/valid.chunk.csv',\n",
        "    encoding='utf-8'\n",
        ")\n",
        "\n",
        "features, labels = preprocess(df)\n",
        "valid_dset = {\n",
        "    'features': np.asarray(features),\n",
        "    'labels': np.asarray(labels)\n",
        "}\n",
        "\n",
        "with gzip.open(base_path + '/datasets/valid.chunk.pickle', 'wb') as f:\n",
        "    pickle.dump(valid_dset, f)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 178830/178830 [00:27<00:00, 6615.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA4hVpINjVsK",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyDEDoMJjcbr",
        "colab_type": "code",
        "outputId": "a11d3817-f761-40b2-e1a7-db719dc49ee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = pd.read_csv(\n",
        "    base_path + '/datasets/test.chunk.csv',\n",
        "    encoding='utf-8'\n",
        ")\n",
        "\n",
        "features, pids = preprocess(df, save_label = False)\n",
        "valid_dset = {\n",
        "    'features': np.asarray(features),\n",
        "    'pids': np.asarray(pids)\n",
        "}\n",
        "\n",
        "with gzip.open(base_path + '/datasets/test.chunk.pickle', 'wb') as f:\n",
        "    pickle.dump(valid_dset, f)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 178830/178830 [00:19<00:00, 9138.51it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}